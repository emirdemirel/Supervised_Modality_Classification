{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHROMA-BASED SUPERVISED MODE RECOGNITION IN THE MULTI-CULTURAL CONTEXT\n",
    "\n",
    "\n",
    "There are 3 main steps in the workflow of this notebook: Feature Extraction, Data Formatting and Classification. \n",
    "---\n",
    "\n",
    "IMPORTANT : All the audio files should be located in the directory specifically according to their modality type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : GATHERING DATA / DOWNLOADING THE AUDIO FILES\n",
    "\n",
    "### Input : \n",
    "#### JSON file :\n",
    "which contains the mbids of audio files, the tonic information, the modality category (e.g. makam, mode, rag, tab, etc. ) In the case of multiple modalities within one song, the start and end times of different sections needs to be specified.\n",
    "\n",
    "#### Directory :\n",
    "Output directory for the dataset to be downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compmusic import dunya\n",
    "from modeUtils.utilities import downloadDataset\n",
    "\n",
    "#token will be shared upon request\n",
    "dunya.set_token('_EnterYourTokenHere_') \n",
    "\n",
    "### Please set the directory for the dataset to be downloaded and the name of the annotations file (JSON).\n",
    "dataDir = 'data/Turkish/'\n",
    "annotationsFile = 'annotations_makam.json'\n",
    "\n",
    "#dataDir = 'data/Hindustani/'\n",
    "#annotationsFile = 'annotations_hindustani.json'\n",
    "\n",
    "#dataDir = 'data/Carnatic/'\n",
    "#annotationsFile = 'annotations_carnatic.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bhairavi', 'Kāṁbhōji', 'Kalyāṇi', 'Kāpi', 'Kamās', 'Tōḍi', 'Pantuvarāḷi', 'Saurāṣtraṁ', 'Śankarābharaṇaṁ', 'Rāgamālika'}\n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "f0f94781-bf80-4248-b475-4a2d9abc7593.mp3\n",
      "Downloading recording : \n",
      "b8e5c465-b4a1-45a5-ba32-824fbd4cfe3a.mp3\n",
      "Downloading recording : \n",
      "523a60bf-3060-4e07-9907-0435b76114be.mp3\n",
      "Downloading recording : \n",
      "4fb8af33-df20-48dc-ad21-0eeb7eb47c91.mp3\n",
      "Downloading recording : \n",
      "9ea8380c-ef54-46ee-8496-8044dac4f8e9.mp3\n",
      "Downloading recording : \n",
      "fcc60a0f-6ced-4a05-b7b8-4dc29d87c546.mp3\n",
      "Downloading recording : \n",
      "52b3552e-dc72-4995-b47d-bf9c4e6d7155.mp3\n",
      "Downloading recording : \n",
      "8c4fc946-e15a-4ffc-9e08-a6f5cd819b9a.mp3\n",
      "Downloading recording : \n",
      "2da84bf7-c3ab-415f-b498-0a3096a8c8d2.mp3\n",
      "Downloading recording : \n",
      "83cd0310-c7f8-4f5c-910f-ee6bba41ed3e.mp3\n",
      "Downloading recording : \n",
      "bc6f2cbc-abe3-4bba-b4b4-a876710b7650.mp3\n",
      "Downloading recording : \n",
      "0d09bf2a-5fef-43df-a50f-a0bfa92af646.mp3\n",
      "Downloading recording : \n",
      "5020d866-f282-41d6-b653-39f930f83c8c.mp3\n",
      "Downloading recording : \n",
      "c4cc6ba4-d456-4fb8-8d31-56a19a7d6312.mp3\n",
      "Downloading recording : \n",
      "e57d03ee-098c-4612-a1aa-988a653bfe41.mp3\n",
      "Downloading recording : \n",
      "49039ca4-4ece-426a-a358-70a61d8f25f2.mp3\n",
      "Downloading recording : \n",
      "37d61e4c-6f7e-42ec-887a-95f84e27238a.mp3\n",
      "Downloading recording : \n",
      "70b0dd53-2a4d-4e59-bc6d-fd92a8b1b3f2.mp3\n",
      "Downloading recording : \n",
      "64fe1441-a9a0-4a3f-86e6-91321958668e.mp3\n",
      "Downloading recording : \n",
      "ee40de57-4e17-4d70-952c-f6919f8d722c.mp3\n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Downloading recording : \n",
      "Dataset downloaded and created in data/Carnatic/ folder\n"
     ]
    }
   ],
   "source": [
    "downloadDataset(annotationsFile,dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : FEATURE EXTRACTION\n",
    "\n",
    "### Input : \n",
    " - JSON file :\n",
    "    which contains the mbids of audio files, the tonic information, the modality category (e.g. makam, mode, rag, tab, etc. ) In the case of multiple modalities within one song, the start and end times of different sections needs to be specified.\n",
    "\n",
    " - numBins(int) : Number of bins in the Chroma Vectors. This is parametrized in consideration of possible microtonalities existing in non-Western music traditions (12,24,36,48, ...)\n",
    " - musicTradition (str) : Name of the modality type specific for the music tradition.\n",
    " \n",
    " \n",
    "         Jazz : Chord-scale\n",
    " \n",
    "         Turkish Classical Music : Makam\n",
    " \n",
    "         Hindustani Classical Music : Rag\n",
    " \n",
    "         Carnatic Classical Music : Raaga\n",
    " \n",
    "         Arab-Andalusian Music : Tab\n",
    "\n",
    "### Output : \n",
    "#### PICKLE file :\n",
    "which has a list of dictionaries where each dictionary contains the Frame-based features, the global statistical features and the ground truth information (tonic, mode type) of each of the audio files.\n",
    "\n",
    "##### IMPORTANT : All the audio files should be located in the directory specifically according to their harmonic mode type.\n",
    "\n",
    "\n",
    "Note that the functions that are used in this tutorial can be found in modeUtils/utilities.py, which is provided in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ChromaFeatureExtraction.py [-h] -t TRADITION -n NUMBEROFBINS -o\r\n",
      "                                  OUTPUT_DIRECTORY\r\n",
      "\r\n",
      "A tool for Chroma (HPCP) Feature Extraction using Essentia library. (FEATURE\r\n",
      "EXTRACTION)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t TRADITION, --tradition TRADITION\r\n",
      "                        Input music tradition to perform the mode\r\n",
      "                        classification task\r\n",
      "  -n NUMBEROFBINS, --numberofBins NUMBEROFBINS\r\n",
      "                        Input number of bins per octave in chroma vectors\r\n",
      "  -o OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY\r\n",
      "                        Output directory for the pickle file that contains the\r\n",
      "                        dataset with the extracted features\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ChromaFeatureExtraction.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis on CarnaticClassicalMusic Tradition.\n",
      "\n",
      "Number of bins per octave in the Chroma Vectors : 12\n",
      "mode categories in the dataset : \n",
      "\n",
      "{'Tōḍi', 'Kamās', 'Bhairavi', 'Kāpi', 'Rāgamālika', 'Kalyāṇi', 'Kāṁbhōji', 'Kāmavardani/Pantuvarāḷi', 'Śankarābharaṇaṁ', 'Saurāṣtraṁ'} \n",
      "\n",
      "Number of Categories in the dataset\n",
      "10\n",
      "Feature Extraction in Process. This might take a while...\n",
      "extracting Features for Raaga :  Saurāṣtraṁ\n",
      "extracting Features for Raaga :  Tōḍi\n"
     ]
    }
   ],
   "source": [
    "!python3 ChromaFeatureExtraction.py -t CarnaticClassicalMusic -n 12 -o 'data/Carnatic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: DataFormatting.py [-h] -i INPUT_FILENAME -f FEATURES_SET -r REGION -c\r\n",
      "                         COMBINED\r\n",
      "\r\n",
      "A tool for converting the feature data into proper format for the machine\r\n",
      "learning pipeline\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -i INPUT_FILENAME, --input_filename INPUT_FILENAME\r\n",
      "                        Name of the input pickle file which is the output file\r\n",
      "                        of ChromaFeatureExtraction.py\r\n",
      "  -f FEATURES_SET, --features_set FEATURES_SET\r\n",
      "                        Set of features to include in the Feature Data.\r\n",
      "                        options = {\"mean\",\"std\",\"all\"}\r\n",
      "  -r REGION, --region REGION\r\n",
      "                        Input region of audios (from the beginning) for\r\n",
      "                        extracting local features. values = [0,1] (region = 1\r\n",
      "                        is equivalent of using the Global Features)\r\n",
      "  -c COMBINED, --combined COMBINED\r\n",
      "                        Input number of bins per octave in chroma vectors SET\r\n",
      "                        combined = 1 FOR PERFORMING CLASSIFICATION USING THE\r\n",
      "                        COMBINATION OF LOCAL AND GLOBAL FEATURES; combined = 0\r\n",
      "                        FOR USING ONLY THE LOCAL FEATURES (except the case\r\n",
      "                        region = 1, which ALREADY corresponds to global\r\n",
      "                        features)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 DataFormatting.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 :  MACHINE LEARNING & AUTOMATIC AUDIO CLASSIFICATION\n",
    "\n",
    "### Input : \n",
    "#### PICKLE file : \n",
    "which is the output of the first notebook in the series (Feature Extraction).\n",
    "\n",
    "\n",
    "### Output :\n",
    "#### CSV file : \n",
    "The output CSV file that contains the FeatureData (X) and the class labels (Y), in appropriate format for the Machine Learning Pipeline.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "\n",
    " - numBins(int) : number of bins in the HPCPvectors ([12,24,36,48])\n",
    " \n",
    " \n",
    " - region(float) : select the first 'x*100'% of the audio files for analysis. The classification is performed using the features that are extracted locally only from specified region of the songs.\n",
    " \n",
    "\n",
    " - combined (boolean) : if combined = 1, classification is performed using the combination of features that are extracted both locally and globally. if combined = 0, only locally obtained features are used for classification. The local region is specified by partSong. Default = True.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rag\n",
      "computing Local Features for the first0.3region of the audio files is COMPLETE \n",
      "\n",
      "Mode types in this dataset:  \n",
      "\n",
      "{'Khamaj', 'Lalat', 'Todi', 'Bageshree', 'Des', 'Bilaskhani todi', 'Yaman kalyan', 'Malkauns', 'Marwa', 'Bhairabi'}\n",
      "Generating CSV file for the features meanLocal+stdGlobal is COMPLETE\n",
      "Generating CSV file for the features stdLocal+meanGlobal is COMPLETE\n",
      "Generating CSV file for the features meanLocal+meanGlobal is COMPLETE\n",
      "Generating CSV file for the features stdLocal+stdGlobal is COMPLETE\n"
     ]
    }
   ],
   "source": [
    "!python3 DataFormatting.py -i 'extractedFeatures_forRagtradition(12bins).pkl' -r 0.3 -c True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Classification.py [-h] -i INPUT_FILENAME -c COMBINED -r REGION\r\n",
      "\r\n",
      "A tool for Chroma (HPCP) Feature Extraction using Essentia\r\n",
      "library.(CLASSIFICATION)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -i INPUT_FILENAME, --input_filename INPUT_FILENAME\r\n",
      "                        Name of the input pickle file which is the output file\r\n",
      "                        of ChromaFeatureExtraction.py\r\n",
      "  -c COMBINED, --combined COMBINED\r\n",
      "                        Input number of bins per octave in chroma vectors SET\r\n",
      "                        combined = 1 FOR PERFORMING CLASSIFICATION USING THE\r\n",
      "                        COMBINATION OF LOCAL AND GLOBAL FEATURES; combined = 0\r\n",
      "                        FOR USING ONLY THE LOCAL FEATURES (except the case\r\n",
      "                        region = 1, which ALREADY corresponds to global\r\n",
      "                        features)\r\n",
      "  -r REGION, --region REGION\r\n",
      "                        Input region of audios (from the beginning) for\r\n",
      "                        extracting local features , SELECT THE REGION OF THE\r\n",
      "                        SONG TO BE ANALYZED LOCALLY. (region = 1 is equivalent\r\n",
      "                        of using the Global Features)\r\n"
     ]
    }
   ],
   "source": [
    "!python3  Classification.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCSVforstage_12bins_meanLocal+meanGlobal.csv\n",
      "DataCSVforstage_12bins_meanLocal+stdGlobal.csv\n",
      "DataCSVforstage_12bins_stdLocal+stdGlobal.csv\n",
      "DataCSVforstage_12bins_stdLocal+meanGlobal.csv\n"
     ]
    }
   ],
   "source": [
    "###CHOOSE THE CSV FILE WITH DESIRED FEATURE SET, TO INPUT FOR THE MACHINE LEARNING PIPELINE\n",
    "import os\n",
    "for file in os.listdir(dataDir):\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process might take a while (5-10 min) \n",
      " CROSS-VALIDATION & TRAINING \n",
      "Accuracy score for the Feature Set stdLocal+stdGlobal : \n",
      "F-measure (mean,std) --- FINAL\n",
      "0.82 0.0749427597141\n",
      "Accuracy (mean,std) FINAL\n",
      "0.82 0.0715891053164\n",
      "['Bageshree', 'Bhairabi', 'Bilaskhani todi', 'Des', 'Khamaj', 'Lalat', 'Malkauns', 'Marwa', 'Todi', 'Yaman kalyan']\n",
      "Confusion matrix, without normalization\n",
      "Figure(900x1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 Classification.py -i 'DataCSVforstage_12bins_stdLocal+stdGlobal.csv' -m Rag -r 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
