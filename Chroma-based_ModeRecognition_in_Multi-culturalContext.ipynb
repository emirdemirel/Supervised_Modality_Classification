{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHROMA-BASED SUPERVISED MODE RECOGNITION IN THE MULTI-CULTURAL CONTEXT\n",
    "\n",
    "\n",
    "There are 3 main steps in the workflow of this notebook: Feature Extraction, Data Formatting and Classification. \n",
    "---\n",
    "\n",
    "IMPORTANT : All the audio files should be located in the directory specifically according to their modality type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : GATHERING DATA / DOWNLOADING THE AUDIO FILES\n",
    "\n",
    "### Input : \n",
    "#### JSON file :\n",
    "which contains the mbids of audio files, the tonic information, the modality category (e.g. makam, mode, rag, tab, etc. ) In the case of multiple modalities within one song, the start and end times of different sections needs to be specified.\n",
    "\n",
    "#### Directory :\n",
    "Output directory for the dataset to be downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compmusic import dunya\n",
    "from modeUtils.utilities import downloadDataset\n",
    "\n",
    "#token will be shared upon request\n",
    "dunya.set_token('ab46d5a96c67cda902dd7b612feccc5e6453e4f1') \n",
    "\n",
    "### Please set the directory for the dataset to be downloaded and the name of the annotations file (JSON).\n",
    "dataDir = 'data/Turkish/'\n",
    "annotationsFile = 'annotations.json'\n",
    "\n",
    "#dataDir = 'data/Hindustani/'\n",
    "#annotationsFile = 'annotations_hindustani.json'\n",
    "\n",
    "#dataDir = 'data/Carnatic/'\n",
    "#annotationsFile = 'annotations_carnatic.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hicazkar', 'Ussak', 'Saba', 'Suzinak', 'Neva', 'Acemasiran', 'Kurdilihicazkar', 'Bestenigar', 'Huseyni', 'Karcigar', 'Beyati', 'Muhayyer', 'Segah', 'Hicaz', 'Huzzam', 'Sultaniyegah', 'Mahur', 'Rast', 'Nihavent', 'Acemkurdi'}\n",
      "Dataset downloaded and created in data/Turkish/ folder\n"
     ]
    }
   ],
   "source": [
    "downloadDataset(annotationsFile,dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : FEATURE EXTRACTION\n",
    "\n",
    "### Input : \n",
    " - JSON file :\n",
    "    which contains the mbids of audio files, the tonic information, the modality category (e.g. makam, mode, rag, tab, etc. ) In the case of multiple modalities within one song, the start and end times of different sections needs to be specified.\n",
    "\n",
    " - numBins(int) : Number of bins in the Chroma Vectors. This is parametrized in consideration of possible microtonalities existing in non-Western music traditions (12,24,36,48, ...)\n",
    " - musicTradition (str) : Name of the modality type specific for the music tradition.\n",
    " \n",
    " \n",
    "         Jazz : Chord-scale\n",
    " \n",
    "         Turkish Classical Music : Makam\n",
    " \n",
    "         Hindustani Classical Music : Rag\n",
    " \n",
    "         Carnatic Classical Music : Raaga\n",
    " \n",
    "         Arab-Andalusian Music : Tab\n",
    "\n",
    "### Output : \n",
    "#### PICKLE file :\n",
    "which has a list of dictionaries where each dictionary contains the Frame-based features, the global statistical features and the ground truth information (tonic, mode type) of each of the audio files.\n",
    "\n",
    "##### IMPORTANT : All the audio files should be located in the directory specifically according to their harmonic mode type.\n",
    "\n",
    "\n",
    "Note that the functions that are used in this tutorial can be found in modeUtils/utilities.py, which is provided in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ChromaFeatureExtraction.py [-h] -t TRADITION -n NUMBEROFBINS -o\r\n",
      "                                  OUTPUT_DIRECTORY\r\n",
      "\r\n",
      "A tool for Chroma (HPCP) Feature Extraction using Essentia library. (FEATURE\r\n",
      "EXTRACTION)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t TRADITION, --tradition TRADITION\r\n",
      "                        Input music tradition to perform the mode\r\n",
      "                        classification task\r\n",
      "  -n NUMBEROFBINS, --numberofBins NUMBEROFBINS\r\n",
      "                        Input number of bins per octave in chroma vectors\r\n",
      "  -o OUTPUT_DIRECTORY, --output_directory OUTPUT_DIRECTORY\r\n",
      "                        Output directory for the pickle file that contains the\r\n",
      "                        dataset with the extracted features\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ChromaFeatureExtraction.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis on TurkishClassicalMusic Tradition.\n",
      "\n",
      "Number of bins per octave in the Chroma Vectors : 48\n",
      "mode categories in the dataset : \n",
      "\n",
      "{'Ussak', 'Nihavent', 'Hicaz', 'Muhayyer', 'Rast', 'Acemkurdi', 'Beyati', 'Mahur', 'Neva', 'Sultaniyegah', 'Segah', 'Suzinak', 'Huseyni', 'Huzzam', 'Kurdilihicazkar', 'Bestenigar', 'Acemasiran', 'Karcigar', 'Saba', 'Hicazkar'} \n",
      "\n",
      "Number of Categories in the dataset\n",
      "20\n",
      "Feature Extraction in Process. This might take a while...\n",
      "extracting Features for Makam :  Acemasiran\n",
      "extracting Features for Makam :  Acemkurdi\n",
      "extracting Features for Makam :  Bestenigar\n",
      "extracting Features for Makam :  Beyati\n",
      "extracting Features for Makam :  Hicaz\n",
      "extracting Features for Makam :  Rast\n",
      "extracting Features for Makam :  Hicaz\n",
      "extracting Features for Makam :  Hicazkar\n",
      "extracting Features for Makam :  Huseyni\n",
      "extracting Features for Makam :  Huzzam\n",
      "extracting Features for Makam :  Karcigar\n",
      "extracting Features for Makam :  Kurdilihicazkar\n",
      "extracting Features for Makam :  Mahur\n",
      "extracting Features for Makam :  Muhayyer\n",
      "extracting Features for Makam :  Neva\n",
      "extracting Features for Makam :  Nihavent\n",
      "extracting Features for Makam :  Rast\n",
      "extracting Features for Makam :  Hicaz\n",
      "extracting Features for Makam :  Rast\n",
      "extracting Features for Makam :  Saba\n",
      "extracting Features for Makam :  Segah\n",
      "extracting Features for Makam :  Sultaniyegah\n",
      "extracting Features for Makam :  Suzinak\n",
      "extracting Features for Makam :  Ussak\n",
      "Features are extracted and saved in a pickle file located in data/Turkish/ directory\n"
     ]
    }
   ],
   "source": [
    "!python3 ChromaFeatureExtraction.py -t TurkishClassicalMusic -n 48 -o 'data/Turkish/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 :  MACHINE LEARNING & AUTOMATIC AUDIO CLASSIFICATION\n",
    "\n",
    "### Input : \n",
    "#### PICKLE file : \n",
    "which is the output of the first notebook in the series (Feature Extraction).\n",
    "\n",
    "\n",
    "### Output :\n",
    "#### CSV file : \n",
    "The output CSV file that contains the FeatureData (X) and the class labels (Y), in appropriate format for the Machine Learning Pipeline.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "\n",
    " - numBins(int) : number of bins in the HPCPvectors ([12,24,36,48])\n",
    " \n",
    " \n",
    " - region(float) : select the first 'x*100'% of the audio files for analysis. The classification is performed using the features that are extracted locally only from specified region of the songs.\n",
    " \n",
    "\n",
    " - combined (boolean) : if combined = 1, classification is performed using the combination of features that are extracted both locally and globally. if combined = 0, only locally obtained features are used for classification. The local region is specified by partSong. Default = True.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: FeatureSelection.py [-h] -i INPUT_FILENAME -r REGION -c COMBINED\r\n",
      "\r\n",
      "A tool for converting the feature data into proper format for the machine\r\n",
      "learning pipeline\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -i INPUT_FILENAME, --input_filename INPUT_FILENAME\r\n",
      "                        Name of the input pickle file which is the output file\r\n",
      "                        of ChromaFeatureExtraction.py\r\n",
      "  -r REGION, --region REGION\r\n",
      "                        Input region of audios (from the beginning) for\r\n",
      "                        extracting local features. values = [0,1] (region = 1\r\n",
      "                        is equivalent of using the Global Features)\r\n",
      "  -c COMBINED, --combined COMBINED\r\n",
      "                        SET combined = 1 FOR PERFORMING CLASSIFICATION USING\r\n",
      "                        THE COMBINATION OF LOCAL AND GLOBAL FEATURES; combined\r\n",
      "                        = 0 FOR USING ONLY THE LOCAL FEATURES (except the case\r\n",
      "                        region = 1, which ALREADY corresponds to global\r\n",
      "                        features)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 FeatureSelection.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makam\n",
      "computing Local Features for the first0.3region of the audio files is COMPLETE \n",
      "\n",
      "Mode types in this dataset:  \n",
      "\n",
      "{'Saba', 'Suzinak', 'Ussak', 'Acemkurdi', 'Neva', 'Segah', 'Sultaniyegah', 'Rast', 'Hicaz', 'Hicazkar', 'Huseyni', 'Huzzam', 'Acemasiran', 'Beyati', 'Kurdilihicazkar', 'Muhayyer', 'Mahur', 'Bestenigar', 'Nihavent', 'Karcigar'}\n",
      "Generating CSV file for the features meanLocal+stdGlobal is COMPLETE\n",
      "Generating CSV file for the features stdLocal+meanGlobal is COMPLETE\n",
      "Generating CSV file for the features meanLocal+meanGlobal is COMPLETE\n",
      "Generating CSV file for the features stdLocal+stdGlobal is COMPLETE\n"
     ]
    }
   ],
   "source": [
    "!python3 FeatureSelection.py -i 'extractedFeatures_forMakamtradition(48bins).pkl' -r 0.3 -c True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Classification.py [-h] -i INPUT_FILENAME -c COMBINED -r REGION\r\n",
      "\r\n",
      "A tool for Chroma (HPCP) Feature Extraction using Essentia\r\n",
      "library.(CLASSIFICATION)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -i INPUT_FILENAME, --input_filename INPUT_FILENAME\r\n",
      "                        Name of the input pickle file which is the output file\r\n",
      "                        of ChromaFeatureExtraction.py\r\n",
      "  -c COMBINED, --combined COMBINED\r\n",
      "                        Input number of bins per octave in chroma vectors SET\r\n",
      "                        combined = 1 FOR PERFORMING CLASSIFICATION USING THE\r\n",
      "                        COMBINATION OF LOCAL AND GLOBAL FEATURES; combined = 0\r\n",
      "                        FOR USING ONLY THE LOCAL FEATURES (except the case\r\n",
      "                        region = 1, which ALREADY corresponds to global\r\n",
      "                        features)\r\n",
      "  -r REGION, --region REGION\r\n",
      "                        Input region of audios (from the beginning) for\r\n",
      "                        extracting local features , SELECT THE REGION OF THE\r\n",
      "                        SONG TO BE ANALYZED LOCALLY. (region = 1 is equivalent\r\n",
      "                        of using the Global Features)\r\n"
     ]
    }
   ],
   "source": [
    "!python3  Classification.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCSVforstage_12bins_meanLocal+meanGlobal.csv\n",
      "DataCSVforstage_12bins_meanLocal+stdGlobal.csv\n",
      "DataCSVforstage_12bins_stdLocal+stdGlobal.csv\n",
      "DataCSVforstage_12bins_stdLocal+meanGlobal.csv\n"
     ]
    }
   ],
   "source": [
    "###CHOOSE THE CSV FILE WITH DESIRED FEATURE SET, TO INPUT FOR THE MACHINE LEARNING PIPELINE\n",
    "import os\n",
    "for file in os.listdir(dataDir):\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process might take a while (5-10 min) \n",
      " CROSS-VALIDATION & TRAINING \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"Classification.py\", line 39, in <module>\n",
      "    main(filename, region, mode)\n",
      "  File \"Classification.py\", line 28, in main\n",
      "    cm,acc,f = machineLearning(dataDir,X,Y,attribute,numBins)\n",
      "  File \"/home/ds/notebooks/modeUtils/utilities.py\", line 597, in machineLearning\n",
      "    param = hyperparameterOptimization(X_train, Y_train, 10)\n",
      "  File \"/home/ds/notebooks/modeUtils/utilities.py\", line 579, in hyperparameterOptimization\n",
      "    grid_search.fit(X_train, Y_train)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\", line 187, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\", line 254, in _dense_fit\n",
      "    max_iter=self.max_iter, random_seed=random_seed)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 Classification.py -i 'DataCSVforstage_48bins_stdLocal+stdGlobal.csv' -m Makam -r 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
